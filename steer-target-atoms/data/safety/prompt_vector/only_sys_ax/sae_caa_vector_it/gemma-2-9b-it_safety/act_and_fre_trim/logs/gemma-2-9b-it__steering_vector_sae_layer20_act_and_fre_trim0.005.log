Namespace(path_dir='/data2/xzwnlp/SaeEdit/ManipulateSAE/data/safety/prompt_vector', sae_path='/disk3/wmr/hugging_cache/gemma-scope-9b-it-res/layer_20/width_16k/average_l0_91', data_name='only_sys_ax', model_name='gemma-2-9b-it', mode='safety', select_type='act_and_fre_trim', layers=[20], hook_module='resid_post', trim=[0.005], re_error_way=False)
re_error_way: False
##########layer20###########
##########layer20###########
no1-torch.norm(caa_vector): 140.50657653808594
type(sae_path)
<class 'str'>

/disk3/wmr/hugging_cache/gemma-scope-9b-it-res/layer_20/width_16k/average_l0_91
act_data.norm：77.01890563964844
re_error: 106.45867156982422

top 10:tensor([16.5754, 13.7673, 11.6919, 10.8159,  7.6730,  7.6625,  6.7130,  6.4621,
         6.2491,  6.1720], grad_fn=<SliceBackward0>)
Negative data:7.211102485656738 

top 10:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')
Positive data:8.5440034866333 

top 10:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')
Activation data:77.01890563964844 

top 10:tensor([14.2552, 13.8605, 13.1357, 11.1726, 10.4817, 10.3747, 10.1459,  9.7048,
         9.1773,  9.0482], device='cuda:0')
mask: tensor(83, device='cuda:0')
act_data != 0:  tensor(104, device='cuda:0')
freq_scores != 0:  tensor(83, device='cuda:0')
频率阈值: 1.0
prune_mask: tensor(83, device='cuda:0')
######### act and fre ########
阈值: 5.5352654457092285
act_top_mask: tensor(82, device='cuda:0')
combined_mask: tensor(74, device='cuda:0')
tensor(571.2888, device='cuda:0')
result_combined.shape torch.Size([3584])
result_combined: tensor([-1.1298, -1.5083, -0.3146,  ..., -1.3941,  0.1107,  1.4640],
       grad_fn=<SqueezeBackward4>)
torch.norm(result_combined) tensor(94.8104, grad_fn=<LinalgVectorNormBackward0>)
########### only act ########
阈值: 5.5352654457092285
act_top_mask: tensor(82, device='cuda:0')
result_act.shape: torch.Size([3584])
result_act: tensor([-0.7767, -1.5551, -0.0228,  ..., -1.0676,  0.4718,  1.7277],
       grad_fn=<SqueezeBackward4>)
########### only fre ########
result_fre.shape: torch.Size([3584])
result_fre: tensor([-0.5722, -1.3077, -0.4003,  ..., -1.1332, -0.1521,  1.8978],
       grad_fn=<SqueezeBackward4>)
