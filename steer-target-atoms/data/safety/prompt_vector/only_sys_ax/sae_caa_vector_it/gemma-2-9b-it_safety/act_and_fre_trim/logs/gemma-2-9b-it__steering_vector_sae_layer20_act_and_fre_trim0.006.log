Namespace(path_dir='/data2/xzwnlp/SaeEdit/ManipulateSAE/data/safety/prompt_vector', sae_path='/disk3/wmr/hugging_cache/gemma-scope-9b-it-res/layer_20/width_16k/average_l0_91', data_name='only_sys_ax', model_name='gemma-2-9b-it', mode='safety', select_type='act_and_fre_trim', layers=[20], hook_module='resid_post', trim=[0.006], re_error_way=False)
re_error_way: False
##########layer20###########
##########layer20###########
no1-torch.norm(caa_vector): 140.50657653808594
type(sae_path)
<class 'str'>

/disk3/wmr/hugging_cache/gemma-scope-9b-it-res/layer_20/width_16k/average_l0_91
act_data.norm：77.01890563964844
re_error: 106.45867156982422

top 10:tensor([16.5754, 13.7673, 11.6919, 10.8159,  7.6730,  7.6625,  6.7130,  6.4621,
         6.2491,  6.1720], grad_fn=<SliceBackward0>)
Negative data:7.211102485656738 

top 10:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')
Positive data:8.5440034866333 

top 10:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')
Activation data:77.01890563964844 

top 10:tensor([14.2552, 13.8605, 13.1357, 11.1726, 10.4817, 10.3747, 10.1459,  9.7048,
         9.1773,  9.0482], device='cuda:0')
mask: tensor(83, device='cuda:0')
act_data != 0:  tensor(104, device='cuda:0')
freq_scores != 0:  tensor(83, device='cuda:0')
频率阈值: 0.0
prune_mask: tensor(16384, device='cuda:0')
######### act and fre ########
阈值: 2.016988754272461
act_top_mask: tensor(99, device='cuda:0')
combined_mask: tensor(99, device='cuda:0')
tensor(721.2108, device='cuda:0')
result_combined.shape torch.Size([3584])
result_combined: tensor([-0.1342, -1.2112,  0.2363,  ..., -0.6788,  0.0343,  2.0124],
       grad_fn=<SqueezeBackward4>)
torch.norm(result_combined) tensor(106.4374, grad_fn=<LinalgVectorNormBackward0>)
########### only act ########
阈值: 2.016988754272461
act_top_mask: tensor(99, device='cuda:0')
result_act.shape: torch.Size([3584])
result_act: tensor([-0.1342, -1.2112,  0.2363,  ..., -0.6788,  0.0343,  2.0124],
       grad_fn=<SqueezeBackward4>)
########### only fre ########
result_fre.shape: torch.Size([3584])
result_fre: tensor([-0.1715, -1.1925,  0.2157,  ..., -0.6642,  0.0257,  2.0604],
       grad_fn=<SqueezeBackward4>)
