{
    "abstract_algebra": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "abstract_algebra",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 17143,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 74446.35622031591
    },
    "anatomy": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "anatomy",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 66985.19833357072,
                "num_examples": 135,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 6981.5649902024825,
                "num_examples": 14,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 28864,
        "dataset_size": 76165.9387623697,
        "size_in_bytes": 105029.9387623697
    },
    "astronomy": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "astronomy",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 75420.3714570574,
                "num_examples": 152,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 7978.931417374265,
                "num_examples": 16,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 39316,
        "dataset_size": 85598.47831302814,
        "size_in_bytes": 124914.47831302814
    },
    "business_ethics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "business_ethics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 31619,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 88922.35622031591
    },
    "clinical_knowledge": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "clinical_knowledge",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 131489.4633955277,
                "num_examples": 265,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 14461.813193990856,
                "num_examples": 29,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 51655,
        "dataset_size": 148150.45202811505,
        "size_in_bytes": 199805.45202811505
    },
    "college_biology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_biology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 71450.87822247542,
                "num_examples": 144,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 7978.931417374265,
                "num_examples": 16,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 43017,
        "dataset_size": 81628.98507844617,
        "size_in_bytes": 124645.98507844617
    },
    "college_chemistry": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_chemistry",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 3989.4657086871325,
                "num_examples": 8,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 26781,
        "dataset_size": 55807.30657955822,
        "size_in_bytes": 82588.30657955822
    },
    "college_computer_science": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_computer_science",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 41132,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 98435.35622031591
    },
    "college_mathematics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_mathematics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 26779,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 84082.35622031591
    },
    "college_medicine": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_medicine",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 85840.29119783506,
                "num_examples": 173,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10971.030698889615,
                "num_examples": 22,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 56303,
        "dataset_size": 99010.49733532117,
        "size_in_bytes": 155313.49733532115
    },
    "college_physics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "college_physics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 50611.0387409201,
                "num_examples": 102,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 29539,
        "dataset_size": 58295.7295289614,
        "size_in_bytes": 87834.7295289614
    },
    "computer_security": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "computer_security",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 30150,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 87453.35622031591
    },
    "conceptual_physics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "conceptual_physics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 116603.86376584532,
                "num_examples": 235,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 12965.76355323318,
                "num_examples": 26,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 34968,
        "dataset_size": 131768.802757675,
        "size_in_bytes": 166736.802757675
    },
    "econometrics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "econometrics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 56565.27859279305,
                "num_examples": 114,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5984.198563030699,
                "num_examples": 12,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 36040,
        "dataset_size": 64748.652594420244,
        "size_in_bytes": 100788.65259442024
    },
    "electrical_engineering": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "electrical_engineering",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 71947.06487679818,
                "num_examples": 145,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 7978.931417374265,
                "num_examples": 16,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 26746,
        "dataset_size": 82125.17173276893,
        "size_in_bytes": 108871.17173276893
    },
    "elementary_mathematics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "elementary_mathematics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 187558.555333998,
                "num_examples": 378,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 20446.011757021555,
                "num_examples": 41,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 54987,
        "dataset_size": 210203.74252961605,
        "size_in_bytes": 265190.74252961605
    },
    "formal_logic": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "formal_logic",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 62519.518444666,
                "num_examples": 126,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 6981.5649902024825,
                "num_examples": 14,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 32884,
        "dataset_size": 71700.25887346498,
        "size_in_bytes": 104584.25887346498
    },
    "global_facts": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "global_facts",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 4986.8321358589155,
                "num_examples": 10,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 19258,
        "dataset_size": 56804.67300673001,
        "size_in_bytes": 76062.67300673001
    },
    "high_school_biology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_biology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 153817.86284005127,
                "num_examples": 310,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 15957.86283474853,
                "num_examples": 32,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 78216,
        "dataset_size": 171974.90111339628,
        "size_in_bytes": 250190.90111339628
    },
    "high_school_chemistry": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_chemistry",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 100725.89082751745,
                "num_examples": 203,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10971.030698889615,
                "num_examples": 22,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 45799,
        "dataset_size": 113896.09696500355,
        "size_in_bytes": 159695.09696500355
    },
    "high_school_computer_science": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_computer_science",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 4488.148922273024,
                "num_examples": 9,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 39072,
        "dataset_size": 56305.989793144116,
        "size_in_bytes": 95377.98979314411
    },
    "high_school_european_history": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_european_history",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 81870.79796325309,
                "num_examples": 165,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 8976.297844546049,
                "num_examples": 18,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 196270,
        "dataset_size": 93046.27124639563,
        "size_in_bytes": 289316.27124639566
    },
    "high_school_geography": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_geography",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 98244.95755590372,
                "num_examples": 198,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10971.030698889615,
                "num_examples": 22,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 38255,
        "dataset_size": 111415.16369338983,
        "size_in_bytes": 149670.16369338983
    },
    "high_school_government_and_politics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_government_and_politics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 95764.02428428999,
                "num_examples": 193,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10472.347485303722,
                "num_examples": 21,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 52963,
        "dataset_size": 108435.5472081902,
        "size_in_bytes": 161398.5472081902
    },
    "high_school_macroeconomics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_macroeconomics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 193512.79518587096,
                "num_examples": 390,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 21443.378184193338,
                "num_examples": 43,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 68758,
        "dataset_size": 217155.34880866078,
        "size_in_bytes": 285913.34880866075
    },
    "high_school_mathematics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_mathematics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 133970.39666714144,
                "num_examples": 270,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 14461.813193990856,
                "num_examples": 29,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 45210,
        "dataset_size": 150631.38529972878,
        "size_in_bytes": 195841.38529972878
    },
    "high_school_microeconomics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_microeconomics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 118092.42372881356,
                "num_examples": 238,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 12965.76355323318,
                "num_examples": 26,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 49885,
        "dataset_size": 133257.36272064323,
        "size_in_bytes": 183142.36272064323
    },
    "high_school_physics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_physics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 74924.18480273466,
                "num_examples": 151,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 8477.614630960157,
                "num_examples": 17,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 45483,
        "dataset_size": 85600.9748722913,
        "size_in_bytes": 131083.97487229132
    },
    "high_school_psychology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_psychology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 270421.7266058966,
                "num_examples": 545,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 29920.992815153495,
                "num_examples": 60,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 113158,
        "dataset_size": 302541.8948596466,
        "size_in_bytes": 415699.8948596466
    },
    "high_school_statistics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_statistics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 107176.31733371314,
                "num_examples": 216,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 11469.713912475507,
                "num_examples": 23,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 74924,
        "dataset_size": 120845.20668478514,
        "size_in_bytes": 195769.20668478514
    },
    "high_school_us_history": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_us_history",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 101222.0774818402,
                "num_examples": 204,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10971.030698889615,
                "num_examples": 22,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 200043,
        "dataset_size": 114392.2836193263,
        "size_in_bytes": 314435.2836193263
    },
    "high_school_world_history": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "high_school_world_history",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 117596.23707449081,
                "num_examples": 237,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 12965.76355323318,
                "num_examples": 26,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 250302,
        "dataset_size": 132761.17606632048,
        "size_in_bytes": 383063.1760663205
    },
    "human_aging": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "human_aging",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 110649.62391397236,
                "num_examples": 223,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 11469.713912475507,
                "num_examples": 23,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 41196,
        "dataset_size": 124318.51326504436,
        "size_in_bytes": 165514.51326504437
    },
    "human_sexuality": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "human_sexuality",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 65000.451716279735,
                "num_examples": 131,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5984.198563030699,
                "num_examples": 12,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 32533,
        "dataset_size": 73183.82571790692,
        "size_in_bytes": 105716.82571790692
    },
    "international_law": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "international_law",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 60038.58517305227,
                "num_examples": 121,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 6482.88177661659,
                "num_examples": 13,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 41592,
        "dataset_size": 68720.64238826535,
        "size_in_bytes": 110312.64238826535
    },
    "jurisprudence": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "jurisprudence",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 53588.15866685657,
                "num_examples": 108,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 33578,
        "dataset_size": 61272.84945489787,
        "size_in_bytes": 94850.84945489786
    },
    "logical_fallacies": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "logical_fallacies",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 80878.4246546076,
                "num_examples": 163,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 8976.297844546049,
                "num_examples": 18,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 33669,
        "dataset_size": 92053.89793775014,
        "size_in_bytes": 125722.89793775014
    },
    "machine_learning": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "machine_learning",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 55572.90528414756,
                "num_examples": 112,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 31121,
        "dataset_size": 63257.596072188855,
        "size_in_bytes": 94378.59607218886
    },
    "management": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "management",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 51107.225395242844,
                "num_examples": 103,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 22828,
        "dataset_size": 58791.91618328414,
        "size_in_bytes": 81619.91618328413
    },
    "marketing": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "marketing",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 116107.67711152257,
                "num_examples": 234,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 12467.08033964729,
                "num_examples": 25,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 49747,
        "dataset_size": 130773.93288976635,
        "size_in_bytes": 180520.93288976635
    },
    "medical_genetics": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "medical_genetics",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 25775,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 83078.35622031591
    },
    "miscellaneous": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "miscellaneous",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 388514.15033471014,
                "num_examples": 783,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 42886.756368386676,
                "num_examples": 86,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 115097,
        "dataset_size": 433600.08214169333,
        "size_in_bytes": 548697.0821416933
    },
    "moral_disputes": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "moral_disputes",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 171680.58239567012,
                "num_examples": 346,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 18949.96211626388,
                "num_examples": 38,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 76043,
        "dataset_size": 192829.71995053047,
        "size_in_bytes": 268872.71995053045
    },
    "moral_scenarios": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "moral_scenarios",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 444087.05561885773,
                "num_examples": 895,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 49868.32135858916,
                "num_examples": 100,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 109869,
        "dataset_size": 496154.5524160434,
        "size_in_bytes": 606023.5524160434
    },
    "nutrition": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "nutrition",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 151833.1162227603,
                "num_examples": 306,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 16456.54604833442,
                "num_examples": 33,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 69050,
        "dataset_size": 170488.8377096912,
        "size_in_bytes": 239538.8377096912
    },
    "philosophy": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "philosophy",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 154314.04949437402,
                "num_examples": 311,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 16955.229261920314,
                "num_examples": 34,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 61912,
        "dataset_size": 173468.45419489083,
        "size_in_bytes": 235380.45419489083
    },
    "prehistory": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "prehistory",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 160764.47600056973,
                "num_examples": 324,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 17453.912475506204,
                "num_examples": 35,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 68826,
        "dataset_size": 180417.5639146724,
        "size_in_bytes": 249243.5639146724
    },
    "professional_accounting": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "professional_accounting",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 139924.6365190144,
                "num_examples": 282,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 15459.179621162639,
                "num_examples": 31,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 87297,
        "dataset_size": 157582.99157877354,
        "size_in_bytes": 244879.99157877354
    },
    "professional_law": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "professional_law",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 761150.3277310925,
                "num_examples": 1534,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 84776.14630960157,
                "num_examples": 170,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 1167828,
        "dataset_size": 848125.6494792906,
        "size_in_bytes": 2015953.6494792905
    },
    "professional_medicine": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "professional_medicine",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 134962.7699757869,
                "num_examples": 272,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 15459.179621162639,
                "num_examples": 31,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 153242,
        "dataset_size": 152621.12503554605,
        "size_in_bytes": 305863.125035546
    },
    "professional_psychology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "professional_psychology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 303666.2324455206,
                "num_examples": 612,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 34409.14173742652,
                "num_examples": 69,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 159357,
        "dataset_size": 340274.5496215436,
        "size_in_bytes": 499631.5496215436
    },
    "public_relations": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "public_relations",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 54580.53197550207,
                "num_examples": 110,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5984.198563030699,
                "num_examples": 12,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 31500,
        "dataset_size": 62763.90597712925,
        "size_in_bytes": 94263.90597712925
    },
    "security_studies": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "security_studies",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 121565.73030907278,
                "num_examples": 245,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 13464.446766819072,
                "num_examples": 27,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 140258,
        "dataset_size": 137229.35251448833,
        "size_in_bytes": 277487.35251448833
    },
    "sociology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "sociology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 99733.51751887196,
                "num_examples": 201,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 10971.030698889615,
                "num_examples": 22,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 56480,
        "dataset_size": 112903.72365635807,
        "size_in_bytes": 169383.72365635808
    },
    "us_foreign_policy": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "us_foreign_policy",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 49618.6654322746,
                "num_examples": 100,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5485.515349444808,
                "num_examples": 11,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 29027,
        "dataset_size": 57303.3562203159,
        "size_in_bytes": 86330.35622031591
    },
    "virology": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "virology",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 82366.98461757584,
                "num_examples": 166,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 8976.297844546049,
                "num_examples": 18,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 38229,
        "dataset_size": 93542.45790071838,
        "size_in_bytes": 131771.45790071838
    },
    "world_religions": {
        "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
        "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }\n",
        "homepage": "https://github.com/hendrycks/test",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "mmlu",
        "dataset_name": "mmlu",
        "config_name": "world_religions",
        "version": {
            "version_str": "1.0.0",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 84847.91788918957,
                "num_examples": 171,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 9474.98105813194,
                "num_examples": 19,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 2199.1754385964914,
                "num_examples": 5,
                "dataset_name": null
            }
        },
        "download_size": 27165,
        "dataset_size": 96522.07438591801,
        "size_in_bytes": 123687.07438591801
    },
    "all": {
        "description": "",
        "citation": "",
        "homepage": "",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "_type": "Value"
            },
            "subject": {
                "dtype": "string",
                "_type": "Value"
            },
            "choices": {
                "feature": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "_type": "Sequence"
            },
            "answer": {
                "names": [
                    "A",
                    "B",
                    "C",
                    "D"
                ],
                "_type": "ClassLabel"
            }
        },
        "builder_name": "parquet",
        "dataset_name": "mmlu",
        "config_name": "all",
        "version": {
            "version_str": "0.0.0",
            "major": 0,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 6967453,
                "num_examples": 14042,
                "dataset_name": null
            },
            "validation": {
                "name": "validation",
                "num_bytes": 763484,
                "num_examples": 1531,
                "dataset_name": null
            },
            "dev": {
                "name": "dev",
                "num_bytes": 125353,
                "num_examples": 285,
                "dataset_name": null
            },
            "auxiliary_train": {
                "name": "auxiliary_train",
                "num_bytes": 161000625,
                "num_examples": 99842,
                "dataset_name": null
            }
        },
        "download_size": 51503402,
        "dataset_size": 168856915,
        "size_in_bytes": 220360317
    },
    "auxiliary_train": {
        "description": "",
        "citation": "",
        "homepage": "",
        "license": "",
        "features": {
            "train": {
                "answer": {
                    "dtype": "int64",
                    "_type": "Value"
                },
                "choices": {
                    "feature": {
                        "dtype": "string",
                        "_type": "Value"
                    },
                    "_type": "Sequence"
                },
                "question": {
                    "dtype": "string",
                    "_type": "Value"
                },
                "subject": {
                    "dtype": "string",
                    "_type": "Value"
                }
            }
        },
        "config_name": "auxiliary_train",
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 161000625,
                "num_examples": 99842,
                "dataset_name": "mmlu-test"
            }
        },
        "download_size": 47518592,
        "dataset_size": 161000625,
        "size_in_bytes": 208519217
    }
}