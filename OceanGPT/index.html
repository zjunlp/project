<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Prompting ChatGPT for Multimodal Reasoning and Action">
  <meta name="keywords" content="MM-ReAct, ChatGPT, GPT-4">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OceanGPT:  A Large Language Model for Ocean  Science Tasks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/tool-box.png">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
		/* Define the grid layout */
		.mygrid {
			display: grid;
			grid-template-columns: repeat(3, 1fr);
			grid-gap: 20px;
			width: 80%;
			margin: auto;
		}
		.grid_item {
      background: #FFFFFF;
      opacity: 1;
    }

		/* Define the size of the GIFs */
		.mygif {
			height: auto;
			cursor: pointer;
		}
		
		/* Define the modal styles */
		.modal {
			display: none;
			position: fixed;
			z-index: 1;
			left: 0;
			top: 0;
			width: 100%;
			height: 100%;
			overflow: auto;
			background-color: rgba(0,0,0,0.9);
		}
		
		.modal-content {
			margin: auto;
			display: block;
			width: 80%;
			max-width: 800px;
			max-height: 80%;
		}

    /* Define the full-screen overlay styles */
		.overlay {
			position: fixed;
			z-index: 999;
			left: 0;
			top: 0;
			width: 100%;
			height: 100%;
			overflow: hidden;
			background-color: rgba(0,0,0,0.9);
			display: none;
		}
		
		.overlay img {
			width: auto;
			height: 90%;
			margin: 0 auto;
			display: block;
			max-width: 90%;
			max-height: 90%;
		}

    /* Define the video styles */
		.gifvideo {
			width: 100%;
			height: auto;
		}

		/* Define the progress bar styles */
		.progress {
			width: 100%;
			height: 10px;
			background-color: #ddd;
			position: relative;
		}

		.progress-bar {
			height: 100%;
			background-color: #4CAF50;
			position: absolute;
			top: 0;
			left: 0;
		}
		
		/* Define the close button style */
		.close {
			color: white;
			position: absolute;
			top: 10px;
			right: 25px;
			font-size: 35px;
			font-weight: bold;
			cursor: pointer;
		}
		
		.close:hover,
		.close:focus {
			color: #bbb;
			text-decoration: none;
			cursor: pointer;
		}
	</style>
  </head>
  <body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="width: 110%; margin-left: -5%">OceanGPT:  A Large Language Model for Ocean  Science Tasks</h2>
          <div class="is-size-5">
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Zhen Bi<sup>&#x2660;&#x2661;&#x2664;</sup>
            </span>, 
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Ningyu Zhang<sup>&#x2660;&#x2661;&#x2664;*</sup>
            </span>, 
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Yida Xue<sup>&#x2660;</sup>
            </span>, 
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Yixin Ou<sup>&#x2660;</sup>
            </span>
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Daxiong Ji<sup>&#x2661;&#x2662;</sup>
            </span>
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Guozhou Zheng<sup>&#x2661;&#x2663;</sup>
            </span>
            <span class="author-block" style="color:#00A4EF;font-weight:normal;">
              Huajun Chen<sup>&#x2660;&#x2661;*</sup>
            </span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>&#x2660;</sup>College Computer Science and Technology, Zhejiang University
            </span>
            <span class="author-block">
              <sup>&#x2661;</sup>Donghai Laboratory
            </span>
            <span class="author-block">
              <sup>&#x2662;</sup>Ocean College, Zhejiang University 
            </span>
            <span class="author-block">
              <sup>&#x2663;</sup>Zhoushan-Zhejiang University Ocean Research Center
            </span>
            <span class="author-block">
              <sup>&#x2664;</sup>School of Software Technology, Zhejiang University
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Corresponding Author</span>
           
          </div>


           <div class="column has-text-centered">

            <div class="publication-links">
              
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.02031" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
             
              <span class="link-block">
                <a href="https://github.com/zjunlp/KnowLM" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/zjunlp/OceanGPT-7b" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Hugging Face</span>
                  </a>
              </span>
		    
            </div>

          </div> 


        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" align=middle>
      <!-- <img id="teaser" width="120%" src="./images/figure1.gif"> -->
      <img id="teaser" width="70%" src="./images/capabilities.png">
      <h2 class="subtitle has-text-centered">
        Capabilities of OceanGPT
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <!-- Tools serve as pivotal interfaces that enable humans to understand and reshape the world. With the advent of foundational models, AI systems can utilize tools to expand their capabilities and interact with the world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex problems often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance. This leads to the research question: <b><i>can we teach language models when and how to use tools?</i></b> To meet this need, we propose <b>T</b>ool lea<b>R</b>ning w<b>I</b>th exe<b>C</b>ution f<b>E</b>edback (<b>TRICE</b>), a two-stage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively. Experimental results, backed by further analysis, show that TRICE can make the large language model selectively use tools by improving the accuracy of tool usage while enhancing insufficient tool learning and mitigating excessive reliance on tools.  -->
            (Warning: The model in this paper might produce hallucinations and reader discretion is recommended.) 
	    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though comprehensive experiments, OceanGPT not only shows a higher level of knowledge expertise for oceans science tasks but also gains preliminary embodied intelligence capabilities in ocean technology.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <br>
    <br>
    <!-- Paper Model. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Framework Design</h2>
        <img id="model" width="50%" src="images/procedure.png">
        <p class="has-text-centered">
          The overview of our framework <b>OceanGPT</b>
        </p>
        <br>
        <div class="column has-text-justified">
          <ul>
            <li>
              <!-- <b>Training Stage I: Behavior Cloning.</b>  -->
               <b>OceanGPT</b> is the first ocean LLM, which shows superiority for various ocean science tasks.
              It can answer oceanographic questions according to the instructions of oceanographers, demonstrating expertise in oceanography.
            </li>

                
            <!-- <li>
              <b>Training Stage II: RLEF (Reinforcement Learning with Execution Feedback).</b> We continue to reinforce our model obtained in stageIwith execution feedback by steering it to align with desirable candidate responses. For each question <i>q</i>, we have <i>k</i> different candidate responses <i>y<sub>i</sub></i> (1 ≤ <i>i</i> ≤ <i>k</i>) marshaled from other LLMs (e.g. ChatGPT, LLaMA) or human experts.
              We apply a reward strategy <i>R</i> to score each <i>y<sub>i</sub></i> with <i>r<sub>i</sub></i> = <i>R</i>(<i>a</i>, <i>y<sub>i</sub></i>) where <i>a</i> is the gold answer of question <i>q</i>.
              Our goal is to instruct the model to determine the more desirable response by aligning the LM with scores {<i>r<sub>i</sub></i>}<sub><i>k</i></sub>.
            </li> -->
          </ul>
        </div>

        <img id="model" width="80%" src="images/data_building.png">

        <div class="column has-text-justified">
          <b>DoInstruct</b> is an automated domain instruction evolving framework that constructs the ocean instruction dataset by multi-agent collaboration.
          Our framework effectively alleviates the difficulty of obtaining ocean domain data.
          To effectively simulate and obtain those data, DoInstruct obtain ocean instructions by multi-agent collaboration. 
          Each agent is considered as an expert in a specific domain (topic) and is responsible for generating the corresponding data. 
        </div>

      </div>
    </div>
    <br>
    <br>
    <!-- Paper Model. -->
    
    <!-- Paper Main Results -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Main Results</h2>

        <img id="model" width="80%" src="images/result-1.png">
        <p class="has-text-centered">
          OceanGPT obtains better performance than previous open-sourced LLMs.
        </p>
        <br>

        <img id="model" width="80%" src="images/result-all.png">
        <p class="has-text-centered">
          OceanGPT excels in a range of ocean science tasks.
        </p>
        <br>

        <img id="model" width="30%" src="images/result-3.png">
        <p class="has-text-centered">
          DoInstruct are the effective ocean data generators by multi-agent collaboration.
        </p>
      </div>
    </div>
    <br>
    <br>
    <!-- Paper Main Results -->

    <!-- Paper Analysis -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Exploring the Potential</h2>

        <br>

        <img id="model" width="60%" src="images/result_ocean_science.png">
        <br>
        <div class="column has-text-justified">
          <b>OceanGPT for Ocean Science.</b>
          OceanGPT demonstrates a higher level of knowledge expertise when describing the content of radioactive nuclide research. 
          Its textual content is not only clear in structure and well-organized, but also covers various aspects of radioactive nuclide research, from experimental design to data analysis, and then to risk assessment and disposal guidelines. 
        </div>

        <figure class='half'>
          <img id="model" width="29%" src="images/IMG_1284.GIF">
          <img id="model" width="29%" src="images/IMG_1285.GIF">
        </figure>

        <img id="model" width="60%" src="images/robotics.png">

        <br>
        <div class="column has-text-justified">
          <b>OceanGPT for Ocean Engineering.</b> 
          We integrate machine code instructions into its training data.
          OceanGPT can instruct underwater robots via code or console commands, allowing them to execute basic path-finding operations.
          Though we make preliminary attempts for ocean robot interaction, it paves the way for future advanced oceanic models to undertake intricate robotic control and planning tasks.
        </div>
        
      </div>
    </div>
    <!-- Paper Analysis. -->
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{qiao2023trice,
  author       = {Shuofei Qiao and Honghao Gui and Qianghuai Jia and Huajun Chen and Ningyu Zhang},
  title        = {Making Language Models Better Tool Learners with Execution Feedback},
  journal      = {CoRR},
  year         = {2023},
  eprinttype   = {arXiv},
  eprint       = {2305.13068},
}
</code></pre>
  </div>
</section> -->

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <p>
      This website is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>


<script>
  $(".grid_item").hover(function () {
    $(this).css("background", "#f2f1f1");
    }, 
    function () {
        $(this).css("background", "#FFFFFF"); 
    });

  // Get the modal element
  // var modal = document.getElementById("myModal");
  var overlay = document.getElementById("overlay");
  var span = document.getElementsByClassName("close")[0];


  // Get the image element and the close button element
  //  // display the GIF as it is
  // var img = document.getElementById("modalImg");
  // var img = document.getElementById("overlayImg");
  // Add event listeners to each GIF element
  var gifs = document.getElementsByClassName("mygif");
  for (var i = 0; i < gifs.length; i++) {
  gifs[i].addEventListener("click", function() {
      //  // display the GIF as it is
      // // Set the modal image source and display the modal
      // img.src = this.src;

      // display the GIF as a new image, will play from the begining
      var img = document.createElement("img");
      img.src = this.src.replace(".png", ".gif");

      // Add the img element to the overlay content and display the overlay
      document.getElementById("overlayContent").appendChild(img);
      

      // modal.style.display = "block";
      overlay.style.display = "block";

      // Hide the body overflow
              document.body.style.overflow = "hidden";
  });
  }

  // Add event listener to close button
  span.addEventListener("click", function() {
  // Remove the img element from the overlay content, hide the overlay, and restore the body overflow
          document.getElementById("overlayContent").innerHTML = "";

  // Hide the modal
  // modal.style.display = "none";
  overlay.style.display = "none";
  document.body.style.overflow = "auto";
  });
</script>
</body>
</html>
